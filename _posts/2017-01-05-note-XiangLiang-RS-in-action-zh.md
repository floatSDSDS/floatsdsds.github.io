---
layout: post
title: "《推荐系统实践》阅读笔记"
excerpt: "部分毕设有用的段落和要点摘抄、备忘及自己的使用扩展思路。"
tags:
  - theory
  - Recommender Systems
  - ZH
---


# 推荐系统实践

{:toc}

## 第一章 好的推荐系统
### 1.1推荐系统概述
- 推荐系统由信息过载的问题催生，解决信息过载问题代表性的解决方案是分类目录和搜索引擎（雅虎和谷歌）
- 从物品的角度出发，推荐系统可以更好地发觉物品的长尾（long tail），长尾商品往往代表了一小部分用户的个性化需求，这正是个性化推荐系统主要解决的问题。推荐系统通过发掘用户行为，找到用户个性化需求，从而将长尾商品准确地推荐给需要它的用户。[1,1.1]
- 推荐系统的本质是通过一定的方式将用户和物品联系起来。
- 和搜索引擎不同，个性化推荐系统需要依赖用户的行为数据，一般是作为一个应用存在于不同网站之中。几乎所有的推荐系统应用都是由①前台展示页面；②后台日志系统；③推荐算法三部分组成。

### 1.2 推荐系统评测
- 一个完整的推荐系统一般存在用户，物品，物品提供者三个参与方。在评测一个推荐算法时，需要同时考虑三方利益。
- **预测准确度是推荐系统领域最重要指标**，但准确的预测并不代表好的推荐，比方说，存在有的物品，无论是否推荐，他都准备购买，那么推荐结果可能就是不好的，因为它没有使用户购买更多的书，而仅仅是方便用户购买一本本来就准备购买的书。
#### 1.2.1 评测方法
- 主要由三种评测推荐效果的实验方法，即离线实验（offline experiment），用户调查（user study），和在线实验（online experiment）
    - **离线实验**：不需要对实际系统有控制权，速度快，可以测试大量算法，但无法计算商业上关心的指标，离线指标和商业指标存在差距。
    - 用户调查：在上线测试前一般需要做一次称为用户调查的测试。可以体现用户主观感受，相对在线实验风险低，但用户测试不管对用户还是商家来说成本相对较高，所以很难进行大规模用户调查，测试用户不能随便选择，需要尽量保证测试用户的分布和真实用户的分布相同（如男女，年龄，活跃度）。
    - 在线实验：在完成离线实验和必要用户调查后，可以将推荐系统上线做AB测试，将它和旧的算法进行比较。缺点：周期较长。
        - [AB测试](http://absets.com)：按一定规则将用户随机分成几组，并对不同用户采用不同算法，然后通过统计不同组用户的各种评测指标比较不同算法。
        - 一个大型网站的架构分前端和后端，从后端到前端往往经过很多层，所以不同的AB测试很可能互相干扰。因此，切分流量是AB测试中的关键，不同层之间的流量应该是正交的。

#### 1.2.2 评测指标
- 下面罗列了10个评测指标，实际评测时还要考虑评测维度（用维度，物品维度，时间维度）等。增加评测维度的目的在于知道一个算法在什么情况下性能最好。
1. 用户满意度
    - 用户调查获得用户满意度无法通过离线计算获得，只能通过用户调查或在线实验获得。
2. 预测准确度
    - 最重要的推荐系统离线评测指标。
    - 评分预测：均方根误差（RMSE），平均绝对误差（MAE），如果平分系统是基于整数建立的，那么预测结果取整会降低MAE的误差[2]。
    - **TOP-N推荐**：计算准确率和召回率度量。一般会选取不同的推荐列表长度N，计算出一组准确率/召回率，画出准确率/召回率曲线。
    - **评分预测和TOP-N预测的主要区别在于，TopN预测专注于预测会不会，而不是多少分，**，但我认为，显式反馈并不是无用的。
3. 覆盖率（coverage）描述一个系统对物品长尾的发觉能力。一种改进的评价方法：**统计推荐列表中不同物品出现次数的分布**，研究物品在推荐列表中出现次数的分布描述推荐系统的长尾能力。如果这个分布比较平，那么说明推荐系统的覆盖率较高。如果这个分布比较陡峭，说明推荐系统覆盖率较低。有两个指标可以定义覆盖率：
    - 信息熵
    - 基尼系数（评测推荐系统是否具有马太效应最简单方法）
4. 多样性
    - 推荐列表 中物品之间的不相似性
5. 新颖性
    - 最简单方法：利用推荐结果的平均流行度。[ACM2011年专门的研讨会讨论多样性和新颖性](http://ir.ii.uam.es/divers2011/)
6. 惊喜度
    - 推荐结果和用户历史兴趣不相似，但让用户觉得满意，可以说推荐结果的惊喜度很高[3]。而新颖性只取决于哟用户是否听说过这个推荐结果；
7. 信任度
    - 度量只能通过问卷调查，询问用户是否信任推荐系统的推荐结果
    - 提高推荐系统的信任度方法主要有：①增加推荐系统透明度（推荐解释），②考虑用户的社交网络信息，利用好友信息给用户做推荐。
8. 实时性
    - 新闻，微博这种物品具有时效性
    - 很多推荐系统都会在离线状态每天计算一次用户推荐列表，然后于在线期间将推荐列表展示给用户；
    - 实时性的第二个方面是推荐系统需要能够将新加入系统的物品推荐给用户（考验冷启动问题），可以利用推荐列表中有多大比例的物品是当天新加的来进行评论；
9. 健壮性
    - 抗打击能力，攻击能力（略）
10. 商业目标
    - 是否符合商业目标（略）


- **我们做Top-N推荐，计算准确率，召回率，覆盖率，多样性，新颖性。**
- **离线实验的优化目标可以约化为：覆盖率>A,多样性>B,新颖性>C的限制条件下，尽量优化预测准确度。**

## 第二章 利用用户行为数据
- 2012年时项亮总结的由用户在注册伊始主动说明他们喜欢什么的三个缺点：
    - 自然语言理解用户兴趣尚未成熟（现在已经大有改观）
    - 用户兴趣不断变化，但用户不会不停更新兴趣描述（依旧存在问题，考虑当主体更改为评论）
    - 很多时候用户并不知道自己喜欢什么，很难描述自己喜欢什么（依旧存在）
- 购物车分析

### 2.1 用户行为数据简介
- 用户行为数据最简单存在形式就是日志。
    - 运行过程中产生大量原始日志（raw log）；
    - 原始日志按照用户行为汇总称为会话日志（session log），每个会话表示一次用户行为和对应的服务；
    - 以搜索引擎为例，服务会为每次查询生成一个展示日志（impression log），其中记录了查询和返回结果；
    - 如果用户点击了某个结果，这个点击信息会被服务器截获并存储在点击日志（click log）。
- 用户行为在个性化推荐系统中一般分为显性反馈行为（Explilcitfeedback）和隐性反馈行为（implicitfeedback）

~|显性反馈数据|隐性反馈数据
---|---|---|
用户兴趣|明确|不明确
数量|较少|庞大
存储|数据库|分布式文件系统
实时读取|实时|有延迟
正负反馈|都有|只有正反馈


- 用户行为的一种表示方式

结构|解释
---|---|
user id |产生行为的用户的唯一标识
item id |产生行为的对象的唯一标识
behavior type| 行为的种类（比如是购买还是浏览）
context |产生行为的上下文，包括时间和地点等
behavior weight| 行为的权重（如果是观看视频的行为，那么这个权重可以是观看时长；如果是打分行为，这个权重可以是分数）
behavior content| 行为的内容（如果是评论行为，那么就是评论的文本；如果是打标签的行为，就是标签）

- **部分含有隐性反馈的数据集**
    - [Book-Cross](http://www.informatik.uni-freiburg.de/~cziegler/BX)：只含有用户ID和物品ID，无上下文；
    - [Lastfin](http://www.dtic.upf.edu/~ocelma/MusicRecommendationDataset/lastfm-1K.html)：有上下文（时间戳）；
    - [Netflix Prize](http://netflixprize.com)：包含用户ID，物品ID，用户对物品评分和对平分行为发生的时间戳。

### 2.2 用户行为分析
#### 2.2.1 用户活跃度和物品流行度分布
- 很多关于互联网数据的研究罚下你，互联网上很多数据分布都满足Power Law分布，这个分布在互联网领域也称为长尾分布。

$$f(x)=ax^k$$

- 长尾分布很早就被统计学家注意到了，如1932年哈佛大学语言学家研究发现每个单词出现的频率和它在热门排行榜中排名常数次数幂成反比，**考虑观察就餐点和口味的分布**例：本书p39(56)，长尾分布在双对数曲线上应该呈直线。

#### 2.2.2 用户活跃度和物品流行度关系
- 一般认为，新用户倾向于浏览热门的物品，因为他们对网站还不熟悉，只能点击首页的热门物品，而老用户会逐渐开始浏览冷门的物品。即用户越活跃，越倾向于浏览冷门的物品。
- 协同过滤算法：
    - 基于邻域(neighborhood-based)（基于物品和基于用户的协同过滤归在这一类）
    - 隐语义模型(latent factor model)
    - 随机游走(random walk on graph)

### 2.3 基于邻域的算法
> - **基于用户的协同过滤算法是推荐系统中最古老的算法。可以不夸张地说，这个算法的诞生标
志了推荐系统的诞生。该算法在1992年被提出，并应用于邮件过滤系统，**
> - 1994年被GroupLens用
于新闻过滤。在此之后直到2000年，该算法都是推荐系统领域最著名的算法

#### 2.3.1 基于用户的协同过滤（UserCF）：
- 如[08年Digg](http://about.digg.com/blog/digg-recommendation-engine-updates)使用了UserCF提升了用户的行为。
- UserCF步骤
    1. 找到和目标用户兴趣相似的用户集合。（如JAccard，余弦相似度）
    2. 找到这个集合中的用户喜欢的，且目标用户没有听说过的物品推荐给目标用户。
    - 该代码对两两用户都利用余弦相似度计算相似度。这种方法的时间复杂度是$O(|U|\*|U|)$，这在用户数很大时非常耗时。事实上，很多用户相互之间并没有对同样的物品产生过行为，即很多时候两用户之间交集为零。上面的算法将很多时间浪费在了计算这种用户之间的相似度上。如果换一个思路，我们可以首先计算出购买物品不为零的用户对(u,v)，再对这种情况单独处理。优化算法如下：p47(64)：
        1. 可以首先建立物品到用户的倒排表，对于每个物品都保存对该物品产生过行为的用户的列表。
        2. 令稀疏矩阵C[u][v]为|N(u)∩N(v)|，那么，假设用户u和用户v同时属于倒排表中K个物品对应的用户列表，就有C[u][v]=K。
        3. 从而，可以扫描倒排表中每个物品对应的用户列表，将用户列表中的两两用户对应的C[u][v]加1，最终就可以得到所有用户之间不为0的C[u][v]；

- 重要参数K（推荐最相似的K个用户），如果K越大，参考的人越多，结果就越来越趋近于全局热门的物品。

#### 2.3.2其他算法
- Random：随机挑选用户每产生过行为的物品，准确率和召回率低，覆盖度高，平均流行度低；
- MostPopular：按照流行度给用户推荐他们没有产生过行为中最热门的10个物品，准确率和召回率高，覆盖率低，结果流行度高；

#### 2.3.3 基于物品的协同过滤ItemCF
- ItemCF并不利用物品的内容属性计算物品之间的相似度，主要通过分析用户的行为记录计算物品间相似度。如03年亚马逊[5]
- 基础算法
    1. 计算物品之间的相似度；
    2. 根据物品的相似度和用户的历史行为给用户生成推荐列表；
- 改进算法：
    1. 惩罚热门物品（防止任何物品都和热门物品相似度高）p53(p70)
    2. 惩罚买了很多物品的用户（IUF[6]），对于过于活跃的用户，为了防止矩阵过于稠密，可以直接忽略他的兴趣列表（可设定阈值）；ItemCF-IUF提高推荐结果覆盖率，降低推荐结果流行度。
- 一般来说，同系列同主角同风格同国家地区的电影会有比较大的相似度（协同过滤角度的相似度）
- 重要参数K
- 如果将ItemCF相似度矩阵最大值归一化，可以提高推荐的准确率[7]
- 改进UserCF-IIF：对热门物品的惩罚[4]
- 那么，对于两个不同的类，什么样的类其类内物品之间的相似度高，什么样的类其类内物品相似度低呢？一般来说，热门的类其类内物品相似度一般比较大。如果不进行归一化，就会推荐比较热门的类里面的物品，而这些物品也是比较热门的。因此，推荐的覆盖率就比较低。相反，如果进行相似度的归一化，则可以提高推荐系统的覆盖率。

#### 2.3.4 UserCF和ItemCF的历史和比较
- UserCF是推荐系统领域较为古老的算法，1992年就已经在电子邮件的个性化推荐系统Tapestry中得到了应用，1994年被GroupLens①用来实现新闻的个性化推荐，后来被著名的文章分
享网站Digg用来给用户推荐个性化的网络文章。ItemCF则是相对比较新的算法，在著名的电子商务网站亚马逊和DVD租赁网站Netflix中得到了广泛应用[5]。
- UserCF给用户推荐那些和他有共同兴
趣爱好的用户喜欢的物品，而ItemCF给用户推荐那些和他之前喜欢的物品类似的物品。从这个算法的原理可以看到，UserCF的推荐结果着重于反映和用户兴趣相似的小群体的热点，而ItemCF的推荐结果着重于维系用户的历史兴趣，**UserCF的推荐更社会化，反映了用户所在的小型兴趣群体中物品的热门程度，而ItemCF的推荐更加个性化，反映了用户自己的兴趣传承。**
- 而ItemCF需要维护一张物品相关度的表，如果物品更新很快，那么这张表也需要很快更新，这在技术上很难实现。绝大多数物品相关度表都只能做到一天一次更新，所以新闻，推荐类网站不太可能使用ItemCF。从存储的角度说，如果用户很多，那么维护用户兴趣相似度矩阵需要很大的空间，同理，如果物品很多，那么维护物品相似度矩阵代价较大。

~|UserCF |ItemCF|
---|---|---|
性能 |适用于用户较少的场合，如果用户很多，计算用户相似度矩阵代价很大|适用于物品数明显小于用户数的场合，如果物品很多（网页），计算物品相似度矩阵代价很大
领域| 时效性较强，用户个性化兴趣不太明显的领域| 长尾物品丰富，用户个性化需求强烈的领域|
实时性| 用户有新行为，不一定造成推荐结果的立即变化|用户有新行为，一定会导致推荐结果的实时变化
冷启动 |在新用户对很少的物品产生行为后，不能立即对他进行个性化推荐，因为用户相似度表是每隔一段时间离线计算的|新用户只要对一个物品产生行为，就可以给他推荐和该物品相关的其他物品
-|新物品上线后一段时间，一旦有用户对物品产生行为，就可以将新物品推荐给和对它产生行为的用户兴趣相似的其他用户|但没有办法在不离线更新物品相似度表的情况下将新物品推荐给用户
推荐理由 |很难提供令用户信服的推荐解释|利用用户的历史行为给用户做推荐解释，可以令用户比较信服

- 一般来说，这两种算法经过优化后，最终得到的离线性能是最近似的

### 2.4 隐语义模型（LFM）
#### 2.4.1 方法
- 隐语义模型（latent factor model）最早在文本挖掘领域被提出，用于找到文本的隐含语义。
- 相关名词，模型和方法：
    - LSI
    - pLSA
    - LDA
    - latent class model
    - latent Topic Model
    - 矩阵分解
- 核心思想是通过隐含特征（latent factor）联系用户兴趣和物品。
- 除了UserCF和ItemCF，还可以先得到用户的兴趣分类，然后从分类中挑选他可能喜欢的物品。问题拆解：
    - 如何给物品分类
    - 如何确定用户对哪些类物品感兴趣，以及感兴趣程度
    - 对于一个给定的类，选择哪些物品进行推荐，如何确定物品在一个类中的权重。
- 专家系统的问题：
    - 编辑的意见不能代表各种用户的意见，同一种物品可能有多个分类；
    - 分类需要有不同的粒度，比如，初学者，新用户可以按粗粒度的推荐，而资深研究人员可以做细粒度推荐；
    - 多维度分类困难；
    - 决定某物品在一个分类中权重困难；
- 解决上面问题的方法：隐语义分析技术。**基于用户行为统计的自动聚类**；
    - 隐含语义分析技术和ItemCF在物品分类方面的思想类似；
    - LFM允许我们指定最终有多少分类
    - LFM给出的分类是多维度的
    - LFM统计用户行为决定物品在每个类中的权重；
    - LFM解决负样本问题：“One-Class Collaborative Filtering”
        - 把u没有过行为的物品作为负样本
        - 从u没有过行为的物品中均匀采样出一些物品作为负样本
        - 从u没有过行为的物品中采样出一些物品作为负样本，但采样时，保证每个用户的正负样本数目相当。
        - 从u没有过行为的物品中采样出一些物品作为负样本，但采样时偏重采样不热门的物品。
    - 上述问题在2011年KDD Cup推荐系统比赛中，实践得到结论，采集负样本应遵循上述后两条规则。
- LFM重要参数：
    - 隐特征学习个数F
    - 学习速率alpha
    - 正则化参数lambda
    - 负样本/正样本比例ratio（实验发现ratio影响大）
- 当数据集非常稀疏时，LFM性能会明显下降，甚至不如UserCF和ItemCF的性能。

#### 2.4.2 与邻域方法比较
- 理论基础：LFM是学习方法，邻域方法不是
- 空间复杂度（所需存储空间）：
    - UserCF：O( M^2 )
    - ItemCF：O( N^2 )
    - LFM：O(F(M+N))，在M/N很大时可以很好地节省离线计算的内存。
- 时间复杂度：
    - UserCF：O( N*(K/N)^2 )
    - ItemCF：O( M*(K/M)^2 )
    - LFM：O( KFS )
    - 如果K/N>FS，UserCF时间复杂度低，K/M>FS，ItemCF时间复杂度低；（但总体上同数量级）
- LFM实时性不好。

### 2.5 基于图的模型
- 本章以用户-物品二分图为例
- 一般来说图中顶点的相关性主要取决于下面三个因素：
    - 两个顶点之间的路径数
    - 两个顶点之间的路径长度
    - 两个顶点之间路径经过的顶点
- 一般来说相关性高的一对顶点具有如下特征：
    - 两顶点之间有很多路径相连；
    - 连接两顶点之间路径长度都比较短
    - **两顶点之间路径不会经过出度比较大的顶点**
- 基于随机游走的方法时间复杂度高的解决办法：
    - 减少迭代次数
    - 从矩阵论出发，重新设计算法
- 对于稀疏矩阵的快速求逆[8]


## 第三章 推荐系统冷启动问题

- 冷启动问题主要分三类：
  - 用户冷启动
  - 物品冷启动
  - 系统冷启动
- 对应的解决方法：
  - 提供非个性化的推荐，当用户数据收集到一定程度转为个性化推荐
  - 利用注册时所填信息做粗粒度个性化
  - 利用社交网络账号登录导入社交网络上好友信息，给其推荐好友喜欢物品
  - 要求用户在登陆时对一些物品做反馈（平分，评价），给用户推荐那些和这些物品相似的物品。
  - 利用新加入物品的内容信息
  - 引入专家知识建立物品相关度表

### 3.1 利用用户内容信息
- 用户注册信息分三种：
  - 人口统计学信息（基于人口统计学的系统推荐）**利用人口统计学信息先对用户分类，利用物品标签对物品分类（categories）**，包括年龄，性别，工作，学历，居住地，国籍，民族等
  - 用户兴趣描述
  - 从其他网站导入的用户站外行为数据，社交数据
- 利用这些数据构建性别-电视剧相关表，年龄-电视剧相关表，职业-电视剧相关表等。
- 获取喜欢物品i的用户中具有特征f的比例：

$$p(f,i)=\frac{|N(i)\cap U(f)|}{|N(i)+\alpha|}$$

- 包含了人口统计学信息的数据集：
    - BookCrossing
    - Lastfm
- 基于人口统计学信息的算法：xxMostPopular（感觉和UserCF后半部相通）
- 用决策树选择启动物品集合[9]

### 3.2 利用物品内容信息
- 使用自然语言技术抽取关键词，生成关键词向量（为物品分关键词）最后对关键词进行排名，计算每个关键词的权重，可以勇信息检索领域著名的TF-IDF公式计算词的权重。
- 用户的行为强烈受某一内容属性的影响，那么内容过滤的算法还是可以在精度上超过协同过滤算法的。
- 向量空间模型可以在内容数据风服时获得比较好的效果。（如长文本）
- 如何建立文章，话题和关键词是话题模型研究的重点。话题模型如LDA，由三种元素，即文档，话题和词语。每一篇文档表现为词的集合，这称为词袋模型。使用LDA计算物品的内容相似度时，我们可以先计算出物品在话题上的分布，然后利用两个物品的话题分布计算物品的相似度。比如，如果两个物品的话题分布相似，则认为两个物品具有较高的相似度，反之则认为两个物品的相似度低，计算分布相似度可以利用KL散度。
- 音乐基因*business基因，对基因分类（专家系统+机器学习，[jinni](http://jinni.com/movie-genome.html)）

## 第四章 利用用户标签数据
- 推荐系统基本上通过三种方式联系用户兴趣和物品。即
    - 用户喜欢过的物品
    - 和用户兴趣相似的其他用户
    - 通过一些特征
- 这里所说的标签是指用户打的标签，而yelp数据集没有用户打的标签，略。

## 第五章 利用上下文信息
- 可以参考Alexander Tuzhilin①教授的一篇综述“Context Aware Recommender Systems”。Alexander Tuzhilin教授最近几年和他的学生们对上下文相关的推荐算法进行了深入研究
- 重要的上下文：地点，时间，用户心情

### 5.1 时间上下文

- 时间对用户兴趣的影响表现在以下几个方面：
    - 用户的兴趣是变化的
    - 物品也是有生命周期的
    - 季节效应
- **在给定时间信息后，推荐系统从一个静态的系统变成了一个时变的系统，而用户行为数据也变成了时间序列。研究一个时变系统，需要首先研究这个系统的时间特性。包含时间信息的哟用户行为数据集由一系列三元组(u,i,t)组成。**
- 书中通过统计如下信息研究系统的时间特性（yelp数据集都没有条件进行）：
    - 数据集每天独立用户数的增长情况
    - 系统的物品变化情况
    - 用户访问情况
- 参考数据集：
    - Delicious
- 物品生存周期和系统的时效性
    - 物品平均在线天数
    - 相隔一定天数系统物品流行度向量的平均相似度
- 推荐系统的实时性
- 推荐算法的时间多样性（提高的解决方案），对不同算法的时间多样性Neal Lathia博士在博士论文中进行了深入探讨[10]
    - 需要保证推荐系统能够在用户有了新的行为后及时调整推荐结果，使推荐结果满足用户最近的兴趣；
    - 其次，需要保证推荐系统在用户没有新的行为时也能够经常变化一下结果，具有一定的时间多样性。
- 保证时间多样性的具体思路：
    - 生成推荐结果时加入一定随机性
    - **为用户近期看过但没有行为的物品降权**
    - 每天给用户使用不同的推荐算法（随机挑选喵喵喵？）
- 时间上下文推荐算法
    1. 最近最热门
    2. 时间上下文相关的ItemCF（用户在相隔很短的时间内喜欢的物品具有更高的相似度，加重用户近期行为的权重）

$$    sim(i,j)=\frac{\sum_{u\in N(i)\cap N(j)}f(|t_{ui}-t_{uj}|)}{\sqrt{|N(i)||N(j)|}}
$$
    其中f(tui-tuj)可使用不同的数学衰减函数
    3. 时间上下文相关的UserCF
    - 比如，16年的A与12年的B相似，这种感觉
- 时间段图模型
- KDD会议上曾经提出一个时间段图模型[11]，将时间信息建模到图模型中。(结合路径融合算法，首先提取出两定点之间长度小于一个阈值的所有路径，然后根据每条路径经过的顶点给每条路径赋予一定的权重，最后将两个顶点之间所有路径的权重值和作为两个顶点的相关度)
- 部分算法列表：
    - Pop：给用户推荐当天最热门的物品
    - TItemCF：融合时间信息的ItemCF算法
    - TUserCF：融合时间信息的UserCF
    - ItemCF
    - UserCF
    - SGM：时间段图模型
    - USGM：物品时间节点权重为0的时间段图模型
    - ISGM：用户时间节点权重为0的时间段图模型

### 地点上下文
- LBS
- 2010谷歌HotPot
- 明尼苏达大学提出LARS(Location Aware Recommender System)，数据集形式：
    - （用户，用户位置，物品，评分）
    - （用户，物品，物品位置，评分）
    - （用户，用户位置，物品，物品位置，评分）
- 他们发现，用户兴趣和地点相关的两种特征。
    - 兴趣本地化：[12]
    - 活动本地化：一个用户往往在附近的地区活动。通过分析Foursqure的数据，研究人员发现45%的用户其活动范围半径不超过10英，而75%的用户活动半径不超过50英里。因此，在基于位置的推荐中我们需要考虑推荐地点和用户当前地点的距离，不能给用户推荐太远的地方。
- 对有空间属性的数据，LARS的基本思想是将数据集根据用户的位置划分成很多子集（物品数据集呈树状结构），把用户分配到某一个叶子节点中 （可能每个叶子节点上的用户数量很少），这种情况下可能造成叶子节点上数据稀疏。解决办法：金字塔模型，从根节点出发，加权。
- 研究时间上下文的著名文章：[13]
- Evaluating Collaborative Filtering Over Time：论述各种不同推荐算法如何随时间演化。

## 第六章 利用社交网络数据
- 与题目相关结合点不多，略

## 第七章 推荐系统实例
- 推荐系统核心任务被拆解成两部分，一个是如何为给定用户生成特征，一个是如何根据特征找到物品
- 混合推荐：**推荐系统需要由多个推荐引擎组成，每个推荐引擎负责一类特征和一种任务，而推荐系统任务只是将推荐引擎的结果按照一定权重和优先级合并，排序然后返回**
- 多引擎的好处：
    - 对于绝大多数需求需要通过不同的引擎组合实现。
    - 不同引擎代表不同推荐策略，可以实现推荐引擎级别的用户反馈。对不同用户给出不同引擎组合权重。（比如一个引擎用打分，一个引擎用浏览）
- 计算用户的特征向量需要考虑以下因素：
    - 用户行为的种类：成本高代价大的行为往往相对较少但重要
    - 用户行为产生的时间：一般来说越接近的越重要
    - 用户行为的次数
    - 物品的热门程度：用户对一个热门物品产生了行为，往往不能代表用户的个性，反之用户对一个不热门物品产生了行为，说明了用户的个性需求。
- 过滤模块
    - 用户已经产生过行为物品
    - 候选物品以外的物品（来自用户自己的选择）
    - 某些质量很差的物品
- 排名模块

## 第八章 评分预测系统
- 这些名词在本质上应该是同一种思想体系的不同扩展。在推荐系统领域，提的最多的就是潜语义模型和矩阵分解模型。其实，这两个名词说的是一回事，就是如何通过降维的方法将评分矩阵补全。
- 模型融合：
    1. 模型级联融合
    2. 模型加权融合
        - 数据集分为训练集A和测试集B，那么首先需要将训练集A按照与分割AB相同的方法分为A1和A2。A1A2大小相似
        - A1上训练K个不同的预测器，在A2上作出预测。在A2上利用最小二乘法计算出线性融合系数。
        - 在A上训练K个预测器，在B上按线性融合系数得到最终预测。
    3. 用各种魔改模型融合

# reference
[1]Chris Anderson "The Long Tail",2004

[1.1]Chris Anderson "长尾理论", 2006

[2]Major components of the gravity recommendation system

[3]Guy Shani,Asela Gunawardana, Evaluating Recommendation Systems

[4]Empirical Analysis of Predictive Algorithms for Collaborative Filtering, Morgan Kaufmann Publishers，1998

[5]Linden Greg、Smith Brent和 York Jeremy的“Amazon.com Recommendations: Item-to-Item Collaborative Filtering.”（IEEE Internet Computing， 2003）。

[6]John S. Breese、 David Heckerman和 Carl Kadie的“ Empirical Analysis of Predictive Algorithms for Collaborative Filtering”（Morgan Kaufmann Publishers ，1998）。

[7]Evaluation of Item-based Top-N Recommendation Algorithms。

[8]Song Li的“Fast Algorithms For Sparse Matrix Inverse Compuataions”（2009）

[9][Adaptive Bootstrapping of Recommender Systems Using Decision Trees](http://research.yahoo.com/pub/3502)

[10]Neal Lathia、Stephen Hailes、Licia Capra和Xavier Amatriain的“Temporal Diversity in Recommender Systems”（SIGIR 2010）。

[11]Temporal recommendation on graphs via long- and short-term preference fusion（ACM 2010 Article，2010）

[12][A Peek Into Netflix Queues](http://www.nytimes.com/interactive/2010/01/10/nyregion/20100110-netflix-map.html)


[13]Efficient Evaluation of k-Range Nearest Neighbor Queries in Road Networks”（MDM，2012）。
